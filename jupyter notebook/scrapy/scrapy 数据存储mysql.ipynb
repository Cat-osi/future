{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spider.py\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from Cwpjt.items import CwpjtItem\n",
    "\n",
    "class FulongSpider(CrawlSpider):\n",
    "    name = 'fulong'\n",
    "    allowed_domains = ['sina.com.cn']\n",
    "    start_urls = ['http://sina.com.cn/']\n",
    "    'http://news.sina.com.cn/c/2017-05-09/doc-ifyeycte9324112.shtml'\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(allow=('.*?/[0-9]{4}.[0-9]{2}.[0-9]{2}.doc-.*?shtml'),allow_domains=('sina.com.cn')),\n",
    "             callback='parse_item', follow=True),\n",
    "    )\n",
    "\n",
    "    def parse_item(self, response):\n",
    "        i = CwpjtItem()\n",
    "        i['name']=response.xpath('/html/head/title/text()').extract()\n",
    "        i['kws'] = response.xpath('/html/head/meta[@name=\"keywords\"]/@content').extract()\n",
    "        #i['domain_id'] = response.xpath('//input[@id=\"sid\"]/@value').extract()\n",
    "        #i['name'] = response.xpath('//div[@id=\"name\"]').extract()\n",
    "        #i['description'] = response.xpath('//div[@id=\"description\"]').extract()\n",
    "        return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from pymysql import connections\n",
    "class CwpjtPipeline(object):\n",
    "    def __init__(self):\n",
    "        self.conn = pymysql.connect(host='127.0.0.1',user='root',passwd='123456',db ='mydb')\n",
    "        self.cursor = self.conn.cursor()\n",
    "    def process_item(self, item, spider):\n",
    "        name = item['name'][0]\n",
    "        kws = item['kws'][0]\n",
    "        sql =\"insert into hehe(title,kws) VALUES(%s,%s)\"\n",
    "        self.cursor.execute(sql,(name,kws,))\n",
    "        self.conn.commit()\n",
    "        return item\n",
    "    def close_spider(self,spider):\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class CwpjtItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    name = scrapy.Field()\n",
    "    kws = scrapy.Field()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
